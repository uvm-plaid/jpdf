\section{Security Model}
\label{section-pmf}
\label{section-model}

MPC protocols are intended to implement some \emph{ideal
functionality} $\idealf$ with per-client outputs. In the $\minifed$
setting, Given a protocol $\prog$ that implements $\idealf$, with
$\iov(\prog) = S \cup M \cup P \cup O$, the domain of $\idealf$
is $\mems(S)$ and its range is $\mems(O)$.  Real/ideal security in the MPC
setting means that, given $\store \in \mems(S)$, a secure protocol
$\prog$ does not reveal any more information about honest secrets
$\store_H$ to parties in $C$ beyond what is implicitly declassified by
$\idealf(\sigma)$. Security comes in \emph{passive} and
\emph{malicious} flavors, wherein the adversary either follows the
rules or not, respectively. Characterization of both real world
protocol execution and simulation is defined
probabilistically. Following previous work
\cite{barthe2019probabilistic} we use probability mass functions to
express joint dependencies between input and output variables, as a
metric of information leakage.

\subsection{Probability Mass Functions} 

We define discrete joint probability mass functions (pmfs) in a
standard manner but develop some notations that are useful for our
presentation. Firstly, whereas distributions typically map
realizations of random variables to values in $[0..1]$, for
convenience and following \cite{barthe2019probabilistic} we use
memories to represent realizations, so for example given a pmf $\pmf$
over variables $\{ \sx{x}{1}, \mx{y}{2} \}$ we write $\pmf(\{
\elab{\secret{x}}{1} \mapsto 0, \elab{\mesg{y}}{2} \mapsto 1 \})$ to
denote the (joint) probability that $\elab{\secret{x}}{1} = 0 \wedge
\elab{\mesg{y}}{2} = 1$. Recall from Section
\ref{section-lang-semantics} that $\uplus$ denotes the combination of
memories, so for example $\{ \elab{\secret{x}}{1} \mapsto 0\} \uplus
\{\elab{\mesg{y}}{2} \mapsto 1 \} = \{ \elab{\secret{x}}{1} \mapsto 0,
\elab{\mesg{y}}{2} \mapsto 1 \}$.
\begin{definition}
  A \emph{probability mass function} $\pmf$ is a function
  mapping memories in $\mems(X)$ for given variables $X$ to
  values in $\mathbb{R}$ such that:
  $$
  \sum_{\store \in \mems(X)} \pmf(\store) \  = \ 1
  $$
  %The \emph{support} of a distribution is the set of realizations
  %of random variables with non-zero probability:
  %$\support(\pmf) \defeq \{ (v_1,\ldots,v_n) \mid
  %\pmf(\{ x_1 \mapsto v_1, \ldots, x_n \mapsto v_n\}) > 0 \} $
\end{definition}
%To recover succinct and familiar notation, we may omit the domain of a
%distribution when it is clear from an application context-
%i.e., we allow the following sugaring:
%$$
%\pdf{}(\store) \defeq \pdf{\dom(\store)}(\store)
%$$
Now, we can define a notion of marginal and conditional
distributions as follows, which are standard for discrete
probability mass functions. 
\begin{definition}
  Given $\pmf$ with $\dom(\pmf) = \mems(X_2)$, the \emph{marginal distribution}
  of variables $X_1 \subseteq X_2$ in $\pmf$ is denoted $\margd{\pmf}{X_1}$ and defined as follows:
  $$
  \forall \store \in \mems(X_1) \quad . \quad \margd{\pmf}{X_1}(\store) \defeq
  \sum_{\store' \in \mems(X_2-X_1)} \pmf(\store \uplus \store')
  $$
\end{definition}

\begin{definition}
  Given $\pmf$, the \emph{conditional distribution}
  of $X_1$ given $X_2$ where $X_1 \cup X_2 \subseteq \dom(\pmf)$ and $X_1 \cap X_2 = \varnothing$
  is denoted $\condd{\pmf}{X_1}{X_2}$ and defined as follows:
  $$
  \forall \store \in \mems(X_1 \cup X_2)\ .\ 
  \condd{\pmf}{X_1}{X_2}(\store) \defeq
  \begin{cases}
    0 \text{\ if\ } \margd{\pmf}{X_2}(\store_{X_2}) = 0\\
    \margd{\pmf}{X_1 \cup X_2}(\store) / \margd{\pmf}{X_2}(\store_{X_2})\ \text{\ o.w.}
  \end{cases}
  $$
\end{definition}
We also define some convenient syntactic sugarings. The first will allow us to
compare marginal distributions under different realization conditions
(as in, e.g., Definition \ref{definition-NIMO}), the others are standard.
\begin{definition}
  Given $\pmf$, for all $\store_1 \in \mems(X_1)$ and $\store_2 \in \mems(X_2)$ define:
  \begin{enumerate}
  \item $\condd{\pmf}{X_1}{\store_2}(\store_1) \defeq \condd{\pmf}{X_1}{X_2}(\store_1 \uplus \store_2)$
  \item $\pmf(\store_1)  \defeq \margd{\pmf}{X_1}(\store_1)$ 
  \item $\pmf(\store_1|\store_2) \defeq \condd{\pmf}{X_1}{X_2}(\store_1 \uplus \store_2)$
  \end{enumerate}
\end{definition}

\subsection{Basic Distribution of a Protocol}
Now we can define the probability distribution of a program $\prog$,
that we denote $\progtt(\prog)$. Since $\fedcat$ is deterministic the
results of any run are determined by the input values together with
the random tape. And since we constrain programs to not overwrite
views, we are assured that \emph{final} memories contain both a
complete record of all initial secrets as well as views resulting from
communicated information. 

Our semantics require that random tapes contain values for all program
values $\elab{\flip{w}}{\cid}$ sampled from a uniform distribution
over $\mathbb{F}_p$. Input memories also contain input secret values
and possibly other initial view elements as a result of
pre-processing, e.g., Beaver triples for efficient multiplication,
and/or MACed share distributions as in BDOZ/SPDZ
\cite{evans2018pragmatic,10.1007/978-3-030-68869-1_3}. We define
$\runs(\prog)$ as the set of final memories resulting from execution
of $\prog$ given any initial memory, and treat all elements of
$\runs(\prog)$ as equally likely.  This establishes the basic program
distribution that can be marginalized and conditioned to quantify
input/output information dependencies.
%In this
%setting, given a program $\prog$ with $\iov(\prog) = S \cup V$ and
%$\flips(\prog) = F$ we will consider all $\store \in \mems(S \cup V
%\cup F)$ such that $ \config{\store_{S \cup F}}{\prog} \redxs
%\config{\store_}{\varnothing} $ to be equally probable, establishing
%the basic distribution of the program. %From this, we can immediately
%derive the marginal distribution of $S \cup V$ to reason about
%dependencies between secrets and views.
\begin{definition}
  \label{def-progtt}
  \label{def-progd}
  \label{definition-progd}
  Given $\prog$ with $\secrets(\prog) = S$ and $\flips(\prog) = R$ and
  pre-processing predicate $\preproc$ on memories, define:
  $$
  \begin{array}{c}
    \runs(\prog) \defeq \\
    \{ \store \mid \exists \store_1 \in \mems(R) . 
    \exists \store_2 . \preproc(\store_2) \wedge
    %(\dom(\store) = \iov(\prog) \cup R) \wedge
    (\store_1 \uplus \store_2,\prog) \redxs (\store,\varnothing) \}
  \end{array}
  $$
  By default, $\preproc(\store) \iff \dom(\store) = S$, i.e.,
  the initial memory contains all input secrets in a uniform
  marginal distribution. Then the \emph{basic distribution of $\prog$}, written $\progtt(\prog)$, is
  defined such that for all $\store \in \mems(\iov(\prog) \cup R)$:
  $$
  \progtt(\prog)(\store) =  1 / |\runs(\prog)| \ \text{if}\ \store \in \runs(\prog), \text{otherwise}\ 0
  $$
  
  %In some cases, we will also be concerned with the (joint)
  %probabilities of expression interpretation given a preceding program
  %execution, and we write $\progtt(\prog, \be)$ to denote the program
  %distribution $\progtt(\prog;\itv := \be)$ where $\itv$ is a
  %special variable that is never used in programs.
\end{definition}


\subsection{Honest and Corrupt Views}

Information about honest secrets can be revealed to corrupt clients
through messages sent from honest to corrupt clients, and through
publicly broadcast information from honest clients. Dually,
corrupt clients can impact protocol integrity through the messages
sent from corrupt to honest clients, and through publicly broadcast information
from corrupt clients. We call the former \emph{corrupt views}, and
the latter \emph{honest views}. Generally we let $V$ range over sets
of views.
\begin{definition}[Corrupt and Honest Views]
  We let $V$ range over \emph{views} which are sets of messages
  and reveals. Given a program $\prog$ with $\iov(\prog) = S \cup M \cup P \cup O$,
  define $\views(\prog) \defeq M \cup P$, and define $\houtputs$ as
  the messages and reveals in $V = M \cup P$ sent from honest to corrupt
  parties, called \emph{corrupt views}:
  $$
  \begin{array}{lcl}
    \houtputs & \defeq
        & \{\ \rvl{w} \mid\ \reveal{w}{\be}{\cid} \in \prog \wedge \cid \in H \ \}\ \cup \\
      & & \{\ \elab{\mesg{w}}{\cid}\ \mid\  \eassign{\mesg{w}}{\cid}{\be}{\cid'} \in
           \prog \wedge \cid \in C \wedge \cid' \in H \ \} 
  \end{array}
  $$
  and similarly define $\cinputs$ as the subset of $V$ sent from corrupt to honest
  parties, called \emph{honest views}:
  $$
  \begin{array}{lcl}
    \cinputs &  \defeq
        & \{\ \rvl{w} \mid\ \reveal{w}{\be}{\cid} \in \prog \wedge \cid \in C \ \} \ \cup\\
      & & \{\ \elab{\mesg{w}}{\cid}\ \mid\  \eassign{\mesg{w}}{\cid}{\be}{\cid'} \in
              \prog \wedge \cid \in H \wedge \cid' \in C \ \}
  \end{array}
  $$
\end{definition}

\subsection{Passive Correctness and Security}

In the passive setting we assume that $H$ and $C$ follow the
rules of protocols and share messages as expected. A first
consideration is whether a given protocol is \emph{correct}
with respect to an ideal functionality. 
\begin{definition}[Passive Correctness]
  %Given $\prog$ with output variables $\out{1},\ldots,\out{n}$ and ideal
  We say that a protocol $\prog$ is \emph{passive correct} for a functionality
  $\idealf$ iff for all $\store \in \mems(\secrets(\prog))$
  we have $\progtt(\prog)(\idealf(\store) \mid \store) = 1$.
  %with $\idealf(\store) = v_1,\ldots,v_n$ we have
  %$\progtt(\prog)(\out{1} \mapsto v_1,\ldots,\out{n} \mapsto v_n \mid \store) = 1$.
\end{definition}

In the passive setting the simulator must construct a probabilistic
algorithm $\SIM$, aka a \emph{simulation}, that is parameterized by
corrupt inputs and the output of an ideal functionality, and that
returns a reconstruction of corrupt views that is probabilistically
indistinguishable from the corrupt views in the real world protocol
execution.
\begin{definition}
  Given $\store$, and $v$,we write $ \prob(\SIM(\store,v) = \store') $
  to denote the probability that $\SIM(\store,v)$ returns corrupt views
  $\store'$ as a result. We write $\dist(\SIM(\store,v))$ to
  denote the distribution of corrupt views reconstructed by the
  simulation, where for
  all $\store' \in \mems(V)$:
  $$
  \dist(\SIM(\store,v))(\store')\ \defeq\ \prob(\SIM(\store,v) = \store') 
  $$
\end{definition}
Then we can define passive security in the real/ideal
model as follows. 
\begin{definition}[Passive Security]
  Assume given a program $\prog$ that correctly implements an ideal
  functionality $\idealf$, with $\views(\prog) = V$.  Then $\prog$
  is \emph{passive secure in the simulator model} iff there exists
  a simulation $\SIM$ such that for all
  partitions of the federation into honest and corrupt sets $H$ and $C$
  and for all $\store \in \mems(\secrets(\prog))$:
  $$
  \dist(\SIM(\store_{C},\idealf(\store))) = \condd{\progtt(\prog)}{\houtputs}{\store}
  $$
\end{definition}

\subsection{Malicious Security}

In the malicious model we assume that corrupt clients are in
thrall to an adversary $\adversary$ who does not necessarily follow
the rules of the protocol.  We model this by positing a $\arewrite$
function which is given a corrupt memory $\store_C$ and expression
$\be$, and returns a rewritten expression that can be interpreted to
yield a corrupt input. We define the evaluation relation that
incorporates the adversary in Figure \ref{fig-adversary}.

\adversaryfig

A key technical distinction of the malicious setting is that it
typically incorporates ``abort''. Honest parties implement strategies
to detect rule-breaking-- aka \emph{cheating}-- by using, e.g.,
message authentication codes with semi-homomorphic properties as in
BDOZ/SPDZ \cite{10.1007/978-3-030-68869-1_3}. If cheating is detected,
the protocol is aborted. To model this, we extend $\minifed$ with an
\ttt{assert} command and extend the range of memories with
$\bot$. Note that the adversary is free to ignore their own
assertions.
\begin{definition}
  We add assertions of the form $\elab{\assert{\phi(\be)}}{\cid}$ to the command
  syntax of $\minifed$, where $\phi$ is a decidable predicate on
  $\mathbb{F}_p$ and with operational semantics given in Figure
  \ref{fig-adversary}. We also extend the range of memories $\store$
  to $\mathbb{F}_p \cup \{ \bot \}$.
\end{definition}

It is necessary to add $\bot$ to the range of memories since
the possibility of abort needs to be reflected in adversarial
runs of a protocol. We can define $\aruns(\prog)$
as the ``prefix'' memories that result from possibly-aborting
protocols, but we also need to ``pad out'' the memories
of partial runs with $\bot$, as we define in $\botruns(\prog)$,
to properly reflect the contents of views and outputs even in case of abort. 
\begin{definition}
  \label{def-aprogd}
  \label{def-aprogtt}
  \label{definition-aprogd}
  Given program $\prog$ with $\iov(\prog) = S \cup V \cup O$ and $\flips(\prog) = R$, and
  any assumed pre-processing predicate $\preproc$ on memories, define:
  $$
  \begin{array}{c}
    \aruns(\prog) \defeq \\
    \{ \store \mid \exists \store_1 \in \mems(R) . 
    \exists \store_2 . \preproc(\store_2) \wedge
    %(\dom(\store) = \iov(\prog) \cup R) \wedge
    (\store_1 \uplus \store_2,\prog) \aredxs (\store,\varnothing) \}
  \end{array}
  $$
  where by default, $\preproc(\store) \iff \dom(\store) = S$, and also define the following
  which pads out undefined views and outputs with $\bot$:
  $$
  \begin{array}{l}
    \botruns(\prog) \defeq \\
    \qquad \{ \store\{ x_1 \mapsto \bot, \ldots, x_n \mapsto \bot \} \mid \\
    \qquad \phantom{\{} \store \in \aruns(\prog) \wedge \{ x_1,\ldots,x_n\} = (V \cup O) - \dom(\store) \}
  \end{array}
  $$
  Then the \emph{$\adversary$ distribution of $\prog$}, written $\progtt(\prog,\adversary)$, is
  defined such that for all $\store \in \mems(\iov(\prog) \cup R)$:
  $$
  \progtt(\prog,\adversary)(\store) =  1 / |\botruns(\prog)| \ \text{if}\ \store \in \botruns(\prog), \text{otherwise}\ 0
  $$
\end{definition}

Given this preamble, we can define malicious simulation and malicious security
in a standard manner \cite{evans2018pragmatic}, as follows.
\begin{definition}[Malicious Simulation]
  Given a protocol $\prog$ with $\iov(\prog) = S \cup V \cup O$, honest and corrupt 
  clients $H$ and $C$, adversary $\adversary$, and honest inputs
  $\store \in \mems(S_H)$, the \emph{malicious simulation}  $\SIM(\store)$ has three phases:
  \begin{enumerate}
  \item In the first phase $\SIM_1$, $\adversary$ gives the
    simulator some $\store' \in \mems(S_C)$, and the simulator consults an
    oracle to compute $\idealf(\store \uplus \store') \in \mems(O)$.
  \item In the second phase $\SIM_2$, the simulator is given the corrupt
    outputs $\idealf(\store \uplus \store')_C$, which are again given to
    $\adversary$, who decides either to abort or not. If so, then the
    simulator is given $\sigma_{\mathit{out}} \defeq \{ \out{\cid} \mapsto \bot \mid \cid \in H \}$
    and arbitrary internal state $\Sigma$.
    Otherwise the simulator is given $\sigma_{\mathit{out}} \defeq \idealf(\store \uplus \store')_H$
    and $\Sigma$.
  \item In the third phase $\SIM_3$, given $\store_{\mathit{out}}$ and $\Sigma$, the simulator
    finally outputs
    $\store_{\mathit{out}} \uplus \store_{\mathit{views}}$ for some
    calculated $\store_{\mathit{views}} \in \mems(\houtputs)$.
  \end{enumerate}
\end{definition}

\begin{definition}[Malicious Security]
  We write $\dist(\SIM(\store))$ to
  denote the distribution of honest outputs and corrupt views reconstructed by the
  malicious simulation, where for
  all $\store'$:
  $$
  \dist(\SIM(\store))(\store')\ \defeq\ \prob(\SIM(\store) = \store') 
  $$
  Then a protocol $\prog$ with $\iov(\prog) = S \cup V \cup O$ is \emph{malicious
  secure} iff for all $H$, $C$, $\adversary$, and $\store \in \mems(S_H)$:
  $$
  \dist(\SIM(\store)) = \condd{\progtt(\prog,\adversary)}{\houtputs \cup O_H}{\store}
  $$  
\end{definition}
