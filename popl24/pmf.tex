\section{Probability Mass Functions and Program Distributions}
\label{section-pmf}

In order to precisely characterize distributions of secrets and views
in programs, we define probability mass functions in a standard manner,
following the formulation in \ref{barthe2019probabilistic}. In this formulation, memories
denote conjunctions of variable assignments. Intuitively, given a
program $\prog$ with $\iov(\prog) = S \cup V$ and $\store \in
\mems(\iov(\prog))$, when considering the execution of $\prog$
initialized with secrets $\store_S$, we are fundamentally concerned
with the joint probability of the assignments in $\store_V$
conditioned by the assignments $\store_S$. This is because
probabilistic dependence between honest secrets and corrupt views
\emph{is} information leakage. 

\subsection{Basic Definitions} We begin by defining memory probability distributions as follows.
\begin{definition}
  A \emph{memory probability distribution} $\pdf{X}$ is a function
  mapping memories in $\mems(X)$ to values in $[0..1]$, such that:
  $$
  \sum_{\store \in \mems(X)} \pdf{X}(\store) \  = \ 1
  $$
  We call $X$ the \emph{domain} of $\pdf{X}$.
\end{definition}
To recover succinct and familiar notation, we may omit the domain of a
distribution when it is clear from an application context-
i.e., we allow the following sugaring:
$$
\pdf{}(\store) \defeq \pdf{\dom(\store)}(\store)
$$
Now, we can define a notion of marginal and conditional
distributions as follows, which are standard for discrete
probability mass functions. 
\begin{definition}
  Given $X$ the \emph{marginal distribution} of $Y \subseteq X$
  in a distribution $\pdf{X}$, denoted $\margd{\pdf{X}}{Y}$,
  is a distribution with domain $Y$ where for all
  $\store \in \mems(Y)$:
  $$
  (\margd{\pdf{X}}{Y})(\store) =
  \sum_{\store' \in \mems(X-Y)} \pdf{X}(\store \cap \store')
  $$
\end{definition}

\begin{definition}
  Given $\pdf{X}$, its \emph{conditional distribution given
  $\stores$} with $\dom(\stores) = Y$ with $Y \subseteq X$, denoted
  $\condd{\pdf{X}}{\stores}$, is a distribution with domain $X$ where for all
  $\store \in \mems(X)$:
  $$
  (\condd{\pdf{X}}{\stores})(\store) =
  (\sum_{\store' \in \stores} \pdf{X}(\store \cap \store')) /
  (\sum_{\store' \in \stores} (\margd{\pdf{X}}{Y})(\store'))
  $$
  where $\pdf{X}(\store \cap \store')) = 0$ if $\store \cap \store'$ is undefined.
  we write $\condd{\pdf{X}}{\store}$ as an abbreviation for $\condd{\pdf{X}}{\{ \store \}}$.
\end{definition}
To recover familiar notation we allow the following syntactic
sugarings:
\begin{eqnarray*}
\pdf{X}(\store|\store') &\defeq& (\condd{\pdf{X}}{\store})(\store')\\
\pdf{X}(\store) &\defeq& (\margd{\pdf{X}}{\dom(\store)})(\store) \qquad \dom(\store) \subset X
\end{eqnarray*}

\subsection{Program Distributions}
Now we can define the probability distribution of a program $\prog$,
that we denote $\progd(\prog)$. Since $\fedcat$ is deterministic the
results (view assignments) of any run are determined by the input
secrets together with the random tape. And since we constrain programs
to not overwrite views, we are assured that \emph{final} memories
contain both a complete record of all initial secrets as well as views
resulting from communicated information.

We consider random tapes to be selected from a uniform distribution.
In our threat model, we will also assume that any possible initial
secrets are equally likely when formulating the program distribution.
In this setting, given a program $\prog$ with $\iov(\prog) = S \cup
V$ and $\flips(\prog) = F$ we will consider all $\store
\in \mems(S \cup V \cup F)$ such that
$
\config{\store_{S \cup F}}{\prog} \redxs \config{\store_}{\varnothing}
$
to be equally probable, establishing the basic distribution of the
program. From this, we can immediately derive the marginal distribution
of $S \cup V$ to reason about dependencies between secrets and views. 
\begin{definition}
  \label{def-progd}
  Given program $\prog$ with $\iov(\prog) = (S,V)$ and $\flips(\prog) = F$, define $\stores$ as:
  $$
  \stores \defeq \{ \store \mid (\dom(\store) = S \cup V \cup F) \wedge (\store_{S \cup F},\prog) \redxs (\store,\varnothing) \}
  $$
  We note immediately that $|\stores| = 2^{S \cup F}$ given the (deterministic) definition of $\redx$. 
  Define also $\pdf{S \cup V \cup F}$ as the program's \emph{basic distribution} such that for all
  $\store \in \mems(S \cup V \cup F)$:
  $$
  \pdf{S \cup V \cup F}(\store) =
  \begin{cases}
    1 / |\stores| & \text{if}\ \store \in \stores\\
    0 & \text{otherwise}
  \end{cases}
  $$
  Then the \emph{program distribution of $\prog$}, denoted $\progd(\prog)$, is the
  marginal distribution of $S \cup V$ in $\prog$'s basic distribution:
  $$
  \progd(\prog) =  \margd{\pdf{S \cup V \cup F}}{S\cup V}
  $$
  In some cases, we will also be concerned with the (joint)
  probabilities of expression interpretation given a preceding program
  execution, and we write $\progd(\prog, \be)$ to denote the program
  distribution $\progd(\prog;\eassign{\itv}{\be})$ where $\itv$ is a
  special variable that is never used in programs.
\end{definition}


\subsection{Examples}
\label{section-pmf-examples}

In the following, we will refer to program examples defined in
Section \ref{section-minicat-examples} as $\prog_x$, where $x$
is the Example number. 

\begin{fpfig}[t]{Truth table visualization of basic distributions for Examples \ref{example-otp} (L) and \ref{example-lambda-obliv}(a) (R).}{fig-basic-distributions}
{\footnotesize
  $$
  \begin{array}{cc}
    \begin{array}{cccccc}
      \verb+s[1,0]+ & \verb+f[1,0]+ & \verb+v[2,0]+  & \verb+v[2,1]+ & \verb+v[2,2]+ & \verb+v[0,0]+\\
      \hline
      0 & 0 & 0 & 0 & 0 & 0 \\ 
      0 & 1 & 1 & 1 & 0 & 1 \\ 
      1 & 0 & 0 & 1 & 1 & 1 \\ 
      1 & 1 & 1 & 0 & 1 & 0
    \end{array}
    & 
    \begin{array}{ccccc}
      \verb+s[1,s]+ & \verb+f[1,sx]+ & \verb+f[1,sy]+ & \verb+v[0,0]+ & \verb+v[0,1]+ \\
      \hline
      0 & 0 & 0 & 0 & 0 \\ 
      0 & 0 & 1 & 1 & 0 \\ 
      0 & 1 & 0 & 0 & 1 \\ 
      0 & 1 & 1 & 1 & 1 \\
      1 & 0 & 0 & 0 & 0 \\ 
      1 & 0 & 1 & 0 & 0 \\ 
      1 & 1 & 0 & 1 & 1 \\ 
      1 & 1 & 1 & 1 & 1  
    \end{array}
  \end{array}
  $$
}
\end{fpfig}

\paragraph{Example \ref{example-otp} revisited} For small programs it is
helpful to visualize their basic distributions graphically as their
truth tables, where each row corresponds to an equally likely final
memory for the given program. In Figure \ref{fig-basic-distributions}
we show this for Example \ref{example-otp}. In this truth table we can
see that $\sx{1}{0}$ and $\vx{2}{2}$ are perfectly correlated. But
from the adversarial view, $\sx{1}{0}$ is 1 or 0 with equal
probability given any value of $\vx{0}{0}$. More precisely, for any
$\beta_1,\beta_2$ we have:
\begin{mathpar}
(\progd(\prog_{\ref{example-otp}}))(\{\sx{1}{0} \mapsto \beta_1 \}|\{ \vx{0}{0} \mapsto \beta_2 \}) = .5
\end{mathpar}
Note that this corresponds to \emph{perfect secrecy} as described
in \cite{barthe2019probabilistic}.

\paragraph{Example \ref{example-lambda-obliv}(a) revisited} As demonstrated
by Example \ref{example-lambda-obliv} taken from \cite{darais2019language}, it is possible
to leak information probabilistically through observable dependencies
in views. In the basic distribution for Example \ref{example-lambda-obliv}(a)
illustrated in Figure \ref{fig-basic-distributions}, we can see that
the adversarial views $\vx{0}{0}$ and $\vx{0}{1}$ are both 1 in
three different runs of the protocol, and in 2 out of 3 the
honest secret $\sx{1}{0}$ is 1. More precisely:
$$
(\progd(\prog_{\ref{example-lambda-obliv}(a)}))(\{\sx{1}{0} \mapsto 1 \}|\{ \vx{0}{0} \mapsto 1, \vx{0}{1} \mapsto 1 \}) = 2/3
$$
An important point illustrated by this example is that the
probability of values in views, and not just the values themselves,
can release information to the adversary.

\paragraph{Example \ref{example-he} revisited} This standard example
of an MPC secure protocol illustrates how a functionality- in this
case addition (in the binary field)- can be implemented securely. As
mentioned previously, it is \emph{not} the case that \emph{no}
information about input secrets can be revealed to the adversary in
the MPC threat model, since the result of the functionality can itself
reveal information. For example, if the result of addition is $0$,
the adversary knows that two of the clients' secrets must be 0
and the third's must be 1, though not whose is whose- so we can
observe:
\begin{mathpar}
  (\progd(\prog_{\ref{example-he}}))(\{\sx{1}{1} \mapsto 0, \sx{2}{1} \mapsto 1, \sx{3}{1} \mapsto 0 \}|\{ \vx{0}{output} \mapsto 0 \}) = .33
\end{mathpar}
Further, since the standard MPC threat model allows participating
clients to be corrupted we can formally consider the impacts on
information released to the adversary by conditioning the program
distribution on corrupt secrets.  So if we assume client 2
with input secret 1 is corrupted, and we assume the output is 0, then
the adversary knows with certainty that clients 1 and 3 both have input
secrets 0. We can express this as:
$$
\progd(\prog_{\ref{example-he}}))(\{\sx{1}{1} \mapsto 0, \sx{3}{1} \mapsto 0 \}|\{ \sx{2}{1} \mapsto 1, \vx{0}{output} \mapsto 0 \})
= 1
$$ A critical point to note is that this information revealed to the
adversary does not violate MPC security- under the assumption of
public release of the functionality result, and under the assumption
of the possible corruption of clients, this is the cost of doing
business. Rather, the concern is that the protocol does not release
any additional information through information communicated to views
of corrupted parties. Additive secret sharing as realized in
$\prog_{\ref{example-he}}$ is MPC secure in this sense- so for
example, for any $\beta_1$ and $\beta_2$ we have:
$$
\begin{array}{c}
\progd(\prog_{\ref{example-he}}))(\{\sx{1}{1} \mapsto 0 \}|\{ \sx{2}{1} \mapsto 0, \vx{0}{output} \mapsto 0 \})
= \\
\progd(\prog_{\ref{example-he}}))(\{\sx{1}{1} \mapsto 0 \}|\{ \vx{2}{s1} \mapsto \beta_1, \vx{2}{s3} \mapsto \beta_2, \sx{2}{1} \mapsto 0, \vx{0}{output} \mapsto 0 \})
= \\
.5
\end{array}
$$
