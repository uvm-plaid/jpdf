\section{Brute Force Verification}
\label{section-bruteforce}

We have shown how our formulation of program distributions, a precise
definition of intensional protocol behavior, can be used to enforce
the extensional property of MPC security. This intensional description
also has the benefit of being flexible- we can use the same mechanisms
to desribe $\NIMO$, noninterference, perfect secrecy, violations of
obliviousness, etc. These mechanisms can also be exploited to support
automated program analysis.

We initially explore a brute force approach to automatically verifying
program behaviour, the first step of which is to compute the basic
distribution of a program $\prog$. The program distribution
$\progd(\prog)$ can obviously be automatically derived from that, as
can be any of its marginal or conditional distributions. In this
Section we consider two automated mechanisms for deriving
$\progd(\prog)$ in this way. The first is through a straightforward
computation of all final program memories.  The second approach
rewrites $\minifed$ programs to stratified Datalog programs, that are
amenable HPC optimizations such as parallelization and GPU matrix
computations as shown in recent work \cite{XXX}.

The basic distribution of a program $\prog$ is based on the
final memories resulting from any run of $\prog$, denoted
$\runs(\prog)$.
\begin{definition}
  Given $\prog$ with $\iov(\prog) = S \cup V$ and $\flips(\prog) = F$:
  $$
  \runs(\prog) \defeq \{ \store \in \mems(S\cup F \cup V) \mid \config{\store_{S \cup F}}{\prog} \redxs \config{\store}{\varnothing} \}
  $$
\end{definition}
As we've observed, $|\runs(\prog)| = 2^{|S \cup F|}$, so the size of
$\runs(\prog)$ is exponential in the amount of randomness used in the
protocol which generally can be used as a proxy for the protocol
size. In Section \ref{section-composition} we will show how the
methods described here can be used to individually verify
compositional properties of small program components, that guarantee
security properties in larger protocols that combine them. Thus, while
scalability to program size is a clear challenge for our brute force
techniques alone, our ultimate goal is to use them for verification of
compositional properties in larger programs.

\begin{fpfig}[t]{Filtering memories that satisfy a boolean expression.}{fig-solve}
\begin{eqnarray*}
\solve{\stores}{\etrue} &=& \stores\\
\solve{\stores}{\efalse} &=& \varnothing\\
\solve{\stores}{\flip{\cid}{w}} &=& \{ \store \in \stores \mid \store(\flip{\cid}{w}) \} \\
\solve{\stores}{\secret{\cid}{w}} &=& \{ \store \in \stores \mid \store(\secret{\cid}{w}) \} \\
\solve{\stores}{\view{\cid}{w}} &=& \{ \store \in \stores \mid \store(\view{\cid}{w}) \} \\
\solve{\stores}{\oracle{w}} &=& \{ \store \in \stores \mid \store(\oracle{w}) \} \\
\solve{\stores}{(\enot\ \be)} &=& \stores - (\solve{\stores}{\be})\\
\solve{\stores}{(\be_1\ \eand\ \be_2)} &=& (\solve{\stores}{\be_1}) \cap (\solve{\stores}{\be_2}) \\
\solve{\stores}{(\be_1\ \eor\ \be_2)} &=& (\solve{\stores}{\be_1}) \cup (\solve{\stores}{\be_2}) \\
\solve{\stores}{(\be_1\ \exor\ \be_2)} &=&
 ((\solve{\stores}{\be_1}) \cap (\stores - \solve{\stores}{\be_2})) \cup\\
 && ((\stores - \solve{\stores}{\be_1}) \cap (\solve{\stores}{\be_2})) \\
\solve{\stores}{\select{\be_1}{\be_2}{\be_3}} &=&
 ((\solve{\stores}{\be_1}) \cap (\solve{\stores}{\be_2})) \cup \\
 && ((\stores - \solve{\stores}{\be_1}) \cap (\solve{\stores}{\be_3})) \\
\solve{\stores}{\OT{\be_1}{\be_2}{\be_3}} &=&
 ((\solve{\stores}{\be_1}) \cap (\solve{\stores}{\be_2})) \cup\\
 && ((\stores - \solve{\stores}{\be_1}) \cap (\solve{\stores}{\be_3}))
\end{eqnarray*}
\end{fpfig}

\subsection{Method 1: Inductive Computation of $\runs(\prog)$}
\label{section-bruteforce-tables}

Here we describe a straightforward technique for obtaining program
distributions $\progd(\prog)$ through direct computation of
$\runs(\prog)$. Although we could obtain $\runs(\prog)$ simply by
executing $\prog$ given all random tapes and input secrets, the method
we describe here is empirically more efficient (though still
exponential in the length of the random tape), and also supports the
translation to Datalog described in Section
\ref{section-bruteforce-datalog}. An implementation of these
techniques along with Examples from Sections
\ref{section-minicat-examples} and \ref{section-metalang-ygc} is
available online \cite{XXX}.

In Figure \ref{fig-solve} we define the algorithm $\solve{\stores}{\be}$
which filters $\stores$ based on satisfaction of $\be$. This algorithm
is fundamental to our brute force methods. It's correctness is characterized
as follows. 
\begin{lemma}
  \label{lemma-solves}
  For all $\stores$ and $\be$ with $\vars(\be) \subseteq \dom(\stores)$,
  $(\solve{\stores}{\be}) = \{ \store \in \stores \ \mid\ \lcod{\store,\be}{\cid} = 1 \}$
  for some $\cid$.
\end{lemma}
\begin{proof}
  Since we assume safety of programs we can assume that all variables in $\be$ have the
  same owner $\cid$. The result otherwise follows in a straightforward manner by induction
  on $\be$. 
\end{proof}

In order to automatically obtain $\runs(\prog)$, we can do a left
folding of $\solve$ across $\prog$, inductively extending memories
with valid view assignments in the order of their definition.
We can then use this to compute $\progd(\prog)$. We denote
these computations as $\cruns$ and $\cprogd$ respectively.
\begin{lemma}
  \label{lemma-cruns}
  Given $\prog$ where $\iov(\prog) = S \cup V$ and $\flips(\prog) = F$. Define:
  \begin{eqnarray*}
    {tt}\ \ \stores\ (\eassign{\view{\cid}{w}}{\be}) &\defeq& \begin{array}{l}
      \mathrm{let}\ \stores' = \solve{\stores}{\be} \ \mathrm{in}\\
      \ \ \{\extend{\store}{\view{\cid}{w}}{1} \mid \store \in \stores' \}\ \cup\\
      \ \ \{\extend{\store}{\view{\cid}{w}}{0} \mid \store \in \stores - \stores' \}\end{array}\\[2mm]
    \cruns(\prog) &\defeq& \mathit{foldl}\ {tt}\ \mems(S \cup F)\ \prog
  \end{eqnarray*}
  Then $\cruns(\prog) = \runs(\prog)$.
\end{lemma}
\begin{proof}
  By Lemma \ref{lemma-solves} and induction on the length of $\prog$. 
\end{proof}
\begin{lemma}
  \label{lemma-cprogd}
  Given $\prog$ where $\iov(\prog) = S \cup V$ and $\flips(\prog) = F$. Define
  $\cprogd(\prog)$ as the distribution $\margd{\pdf{S \cup F \cup V}}{S\cup V}$,
  where:
  $$
  \pdf{S \cup F \cup V}(\store) = \begin{cases}1/2^{|S \cup F|} & \text{if\ } \store \in
    \cruns(\prog) \\ 0 & \text{otherwise} \end{cases} 
  $$
  Then:
  $$
  \cprogd(\prog) = \progd(\prog)
  $$
\end{lemma}
\begin{proof}
  Immediately by Lemma \ref{lemma-cruns} and Definition \ref{def-progd}.
\end{proof}

We have used the code for $\cruns$ and $\cprogd$ extensively to design and
verify the examples in this paper. We will discuss other examples in
Section \ref{section-composition}, but here we note that we've verified
passive security of Examples \ref{example-he} and \ref{example-OT}-
for the former this is well-known so the result is a simple proof-of-concept,
but the latter is a new (though unsurprising) result, having not been
directly proven in \cite{XXX}. The method for
verifying $\NIMO$ described here generalizes to any $\prog$. 
\begin{lemma}[Automated Verification of Passive Security]
  \label{lemma-bruteforce-nimo}
  $\prog_{\ref{example-he}}$ and $\prog_{\ref{example-OT}};\eassign{\outv}{\vx{2}{mc}}$ are
  passive secure.
\end{lemma}
\begin{proof}
  For both $\prog \in \{
  \prog_{\ref{example-he}},\prog_{\ref{example-OT}};\eassign{\outv}{\vx{2}{mc}}\}$
  we compute $\cruns(\prog)$ and $\cprogd(\prog)$ and then verify
  $\NIMO(\prog)$ using the following algorithm. Given $\iov(\prog) = S
  \cup V$ and $\flips(\prog) = F$, we enumerate all memories $\store
  \in \cruns(\prog)$, then enumerate all partitions of clients into
  sets $H$,$C$ such that $|C| \le |H|$ and $0 \in C$, and then check:
  $$
  \cprogd(\prog)(\store_{S_H}|\store_{S_C \cup \{\outv\}}) =
  \cprogd(\prog)(\store_{S_H}|\store_{S_C \cup V_C})
  $$
  for each $H,C,\store$. The result follows by Lemma \ref{lemma-cprogd}, Lemma \ref{lemma-nimo}, and
  Theorem \ref{theorem-nimo}.
\end{proof}

\subsection{Method 2: Conversion to Datalog}
\label{section-bruteforce-datalog}

Here we show how to rewrite any $\prog$ to an equivalent Datalog
program, which supports application of recent work in linear algebraic
interpretation of Datalog and optimizations of model computation on
high performance computers \cite{XXX}. The method here also enumerates
$\runs(\prog)$ memory-by-memory, rather than in a ``batched'' manner
as in our first method, allowing parallelization of model
computation. The rewriting we describe here is to Datalog with
negation, with a negation-as-failure model, though we can use also
use techniques in \cite{XXX} to also eliminate negation from
resulting programs. \emph{Atoms} are $\minifed$ variables, \emph{literals}
are atoms or negated atoms, and clause bodies are conjunctions of literals.
A \emph{Datalog program} is a list of clauses.
$$
\begin{array}{rclr}
  \alpha &::=& \view{\cid}{w} \mid  \secret{\cid}{w} \mid \flip{\cid}{w} \mid \oracle{w} & \qquad \textit{(atoms)}\\
  \mathit{body} &::=&  \alpha \mid \neg \alpha \mid \alpha \wedge \mathit{body} \mid \neg\alpha \wedge \mathit{body} \mid \varnothing \\
  \mathit{clause} &::=& \alpha \gets \mathit{body}
\end{array}
$$

The first step in converting a protocol $\prot$ to a Datalog
program is to apply $\solve$ ``locally'' to each view definition
in $\prog$, obtaining constraints on memories that satisfy each
view in isolation.  
\begin{lemma} Let $\vars(\be)$ be the variables in $\be$, and define:
$$
{vtt}(\eassign{\view{\cid}{w}}{\be}) \defeq (\view{\cid}{w}, (\solve{(\mems(\vars\ \be))}{\be}))
$$
Then ${vtt}(\eassign{\view{\cid}{w}}{\be}) = (\view{\cid}{w},\stores)$ where $\stores
  = \{ \store \in \mems(\vars\ \be) \mid \lcod{\store,\be}{\cid} = 1 \}$ for some $\cid$.
\end{lemma}
Given this definition, the mapping of ${vtt}$ across a program
$\prog$- i.e., $(\mathit{map}\ {vtt}\ \prog)$- essentially defines the
logic program for ``view atoms'' modulo syntactic conversion. We can
accomplish the latter as follows, where $\datalog(\prog)$ defines the
full conversion.
\begin{definition} We define the conversion from memories to
  literals and clause bodies as follows:
\begin{mathpar}
  \logit{\alpha \mapsto 1} = \alpha

  \logit{\alpha \mapsto 0} = \neg \alpha

  \logit{\{ \alpha_1 \mapsto \beta_1, \ldots, \alpha_n \mapsto \beta_n\}} =
  \logit{\alpha_1 \mapsto \beta_1} \wedge \cdots \wedge \logit{\alpha_n \mapsto \beta_n}
\end{mathpar}
Given pairs $(\alpha,\stores)$ in the range of ${vtt}$, we define the conversion
to clauses as follows:
\begin{mathpar}
  \mathit{clauses}(\alpha,\{ \store_1,...,\store_n \}) = \alpha \gets \logit{\store_1} \vee \cdots \vee \alpha \gets \logit{\store_n}
\end{mathpar}
The $\minifed$-to-Datalog conversion is then defined as:
$$
\datalog(\prog) \defeq  \mathit{map}\ \mathit{clauses}\ (\mathit{map}\ {vtt}\ \prog)
$$
\end{definition}

In addition to converting view definitions to logic clauses, we also need to convert
secrets and random tapes. Since we assume given values for these in an arbitrary run of
the program, we can capture these as a ``fact base'' in our program, where
a fact is a clause of the form $\alpha \gets \varnothing$ and means that $\alpha$
is true in any model of the program. 
\begin{definition}
  Given $\store$, let $\{\alpha_1,\ldots,\alpha_n \} =
  \{ \alpha \in \dom(\store) \mid \store(\alpha) = 1 \}$.
  Then define:
  $$
  \mathit{facts}(\store) = \alpha_1 \gets \varnothing, \ldots, \alpha_n \gets \varnothing
  $$
\end{definition}

For any safe $\prog$ with $\iov(\prog) = S \cup V$ and $\flips(\prog) = F$, and
$\store \in \mems(S \cup F)$, it is the case
that $(\mathit{facts}(\store),\datalog(\prog))$ is a \emph{normal}, \emph{stratified}
(in fact, non-recursive) Datalog program, and so has a unique Least Herbrand Model
and is thus amenable to HPC optimization techniques \cite{aspis2018linear}. 
To compute $\runs(\prog)$, and thus $\progd(\prog)$, we compute
the Least Herbrand Model $\store$ of $(\mathit{facts}(\store'),\datalog(\prog))$
for all $\store' \in \mems(S \cup F)$, observing that model computation for
each $\store'$ can be done in parallel. The following establishes
correctness of this approach.
\begin{lemma}
  For all $\prog$ with $\iov(\prog) = S \cup V$ and $\flips(\prog) = F$,
  $\datalog(\prog)$ is a \emph{normal}, \emph{stratified}
  program \cite{aspis2018linear}, and $\store$ is the unique Least Herbrand
  Model of $(\mathit{facts}(\store_{S \cup F}),\datalog(\prog))$
  iff $\store \in \runs(\prog)$.
\end{lemma}
A full empirical exploration of the application of HPC optimizations
as in \cite{XXX} is beyond the scope of this paper but is a compelling
topic for future work. The reader is referred to \cite{XXX} for empirical
results of HPC optimizations in other logic programming contexts. 
